{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Learn\\\\Code\\\\MetaLearning\\\\Few-Shot-Classification-on-Omniglot-Dataset\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchmeta.datasets import Omniglot\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchmeta.datasets.omniglot.Omniglot at 0x1bbb88e2310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Omniglot(root=os.getcwd(), num_classes_per_task=5, meta_train=True, download=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClassSplitter_' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4996\\3857842217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                \u001b[0mnum_train_per_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                num_test_per_class=1)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0momniglot_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_splitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0momniglot_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ClassSplitter_' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "class_splitter = ClassSplitter(shuffle=True,\n",
    "                               num_train_per_class=1 + 1,\n",
    "                               num_test_per_class=1)\n",
    "omniglot_dataset = class_splitter.split(dataset)\n",
    "\n",
    "omniglot_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the meta-dataset\n",
    "dataset = CombinationMetaDataset(omniglot_dataset,\n",
    "                                 num_classes_per_task=self.num_classes_per_task,\n",
    "                                 num_shots=self.num_shots,\n",
    "                                 num_ways=self.num_ways,\n",
    "                                 tasks_per_epoch=self.num_tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=105x105>,\n",
       " ('images_background/Alphabet_of_the_Magi/character01', 0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__((0, 1, 2, 3, 4)).__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABTElEQVR4nO2Y0Q6DIAxFYdn//3L3MHUVaUvh8rDknhdj1B4obRRLIYQQQgiZo2LDiR38hTVV8wRt0tGbdKFNKv49k3iTufJ40zWV3dm7NO3cNpmeIrxJvqInu7K33yTmlTfYVEq5kideIx83uNc9RD3UrFiUPbHTYdIfXbxOGZd368g6yWgSde4eDNbeTBIbgsFqQTgvd0rRnKp6bmxa5ngynbuWwbDKYarAdMSuI7UXjMM3naJb27v32kNyTT8R4HPNMYkW3d0mznhs0xm0NsdZwipvBPPlZ5o6qVvDMnVEi1I/e4ng5pfKifHWEH3AZLA/J3HOoCZM6AHTFlHX1K4LZp26FVHzlRDnoV8RtQy+KZ6PmRhVDt5ol/LPOwCbpR1Aqh2mTemmS5um2xq5Tn7BAk1BZ6ztCTNtl2pR508XIYQQQgghhBBC/p0Pv/oydAg0/8kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__((0, 1, 2, 3, 4)).__getitem__(19)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABHElEQVR4nO2X2w6DQAhE2ab//8v0qVpdLoNijcmcNyPscJOsIoQQQgghhJC7Ge0nqnPo6wIhUevFu1/HoVUp0Omt3iJk9smbiNgr9HBcUiVUKw0NqF5Y/Qk3LueFIkaGQ2Dp5LT1QLMaUUhhuFmT95ahVdin4qqKzSMlXXNK6oeU198RtZGTtAJuTho+Fl5mSuuHiDbrx66wyzdDN4p1VBE1Smkp4cNdwVAqL1cs57lP9S2OWU85fYXaLxje93RCyHGFNmyMYg57JWBVHsTM6Qqh/vueizkRpUFHN0hTTkBI/6vefUqXjJ2IGBPhXjXPxoBUryfPI/8a5RtGUenY+StPm3Kkk5BSdhA0MuBclf89CCGEEEIIIYQQ8jQ+pegrYhpFPOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__((0, 1, 2, 3, 4)).__getitem__(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from ChatGPT for dattamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmeta.datasets import Omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from torchmeta.transforms import Categorical, ClassSplitter\n",
    "from torchmeta.utils.data import CombinationMetaDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import torch\n",
    "\n",
    "class OmniglotDataModule(LightningDataModule):\n",
    "    def __init__(self, root, num_classes_per_task=5, num_shots=1, num_ways=5, num_tasks=1000):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.num_classes_per_task = num_classes_per_task\n",
    "        self.num_shots = num_shots\n",
    "        self.num_ways = num_ways\n",
    "        self.num_tasks = num_tasks\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        # Load the Omniglot dataset\n",
    "        omniglot_dataset = Omniglot(root=self.root,\n",
    "                                    num_classes_per_task=self.num_classes_per_task,\n",
    "                                    transform=ToTensor(),\n",
    "                                    meta_split=\"train\")\n",
    "        \n",
    "#         # Split the dataset into classes\n",
    "#         omniglot_dataset = ClassSplitter(omniglot_dataset, shuffle=True,\n",
    "#                                        num_train_per_class=self.num_shots + 1,\n",
    "#                                        num_test_per_class=1)\n",
    "#         # omniglot_dataset = class_splitter.split(omniglot_dataset)\n",
    "\n",
    "#         # Create the meta-dataset\n",
    "#         dataset = CombinationMetaDataset(omniglot_dataset,\n",
    "#                                          num_classes_per_task=self.num_classes_per_task)\n",
    "#                                          # num_shots=self.num_shots,\n",
    "#                                          # num_ways=self.num_ways,\n",
    "#                                          # tasks_per_epoch=self.num_tasks)\n",
    "        \n",
    "        self.dataset = omniglot_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Create the data loader\n",
    "        dataloader = BatchMetaDataLoader(self.dataset,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4)\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Create the data loader\n",
    "        dataloader = BatchMetaDataLoader(self.dataset,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4)\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # Create the data loader\n",
    "        dataloader = BatchMetaDataLoader(self.dataset,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4)\n",
    "        return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = OmniglotDataModule(root=os.getcwd(), \n",
    "                        num_classes_per_task=5, \n",
    "                        num_shots=1, \n",
    "                        num_ways=5, \n",
    "                        num_tasks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9474438804480"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                      | 0/9474438804480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), [[('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Balinese/character11',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Futurama/character05',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Malay_(Jawi_-_Arabic)/character39',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',), ('images_background/Braille/character24',)], tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                      | 0/9474438804480 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "with tqdm(dm.train_dataloader(), total=len(dm.train_dataloader())) as pbar:\n",
    "    for batch_idx, batch in enumerate(pbar):        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1, 105, 105])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Balinese/character11',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Ojibwe_(Canadian_Aboriginal_Syllabics)/character10',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Futurama/character05',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Malay_(Jawi_-_Arabic)/character39',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',),\n",
       "  ('images_background/Braille/character24',)],\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9474438804480\n",
      "1183009464\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional, Tuple\n",
    "from torchmeta.datasets import Omniglot\n",
    "from torchvision.transforms import transforms, ToTensor\n",
    "from torchmeta.utils.data import BatchMetaDataLoader, CombinationMetaDataset\n",
    "from torchmeta.transforms import Categorical, Rotation, ClassSplitter\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import torch\n",
    "\n",
    "class MetaDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"data/\",\n",
    "        kshot: int = 5,\n",
    "        nway: int = 5,\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 2,\n",
    "        pin_memory: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        # data transformations\n",
    "        self.transforms = transforms.Compose(\n",
    "            [transforms.Resize(size=28),\n",
    "             transforms.ToTensor(), \n",
    "             transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "\n",
    "        # target transformations\n",
    "        self.target_transform = Categorical()\n",
    "\n",
    "        # class augmentations\n",
    "        self.class_augmentations = [Rotation(angle=a) for a in [90, 180, 270]]\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.hparams.nway\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download data if needed.\n",
    "\n",
    "        Do not use it to assign state (self.x = y).\n",
    "        \"\"\"\n",
    "        Omniglot(root=self.hparams.data_dir, num_classes_per_task=self.hparams.nway, meta_split=\"train\", download=True)\n",
    "        Omniglot(root=self.hparams.data_dir, num_classes_per_task=self.hparams.nway, meta_split=\"val\", download=True)\n",
    "        Omniglot(root=self.hparams.data_dir, num_classes_per_task=self.hparams.nway, meta_split=\"test\", download=True)\n",
    "\n",
    "    def setup_dataset(self, meta_split=\"train\"):\n",
    "        dataset = Omniglot(\n",
    "            root=self.hparams.data_dir,\n",
    "            num_classes_per_task=self.hparams.nway,\n",
    "            # transform=self.transforms,\n",
    "            # target_transform=self.target_transform,\n",
    "            # class_augmentations=self.class_augmentations,\n",
    "            meta_split=meta_split, \n",
    "            download=False)\n",
    "        print(len(dataset))\n",
    "        dataset.seed(42)\n",
    "        dataset = ClassSplitter(\n",
    "            dataset,\n",
    "            shuffle=True,\n",
    "            random_state_seed=42,\n",
    "            num_support_per_class=self.hparams.kshot,\n",
    "            num_query_per_class=self.hparams.kshot)\n",
    "        return dataset\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # load and split datasets only if not loaded already\n",
    "        if stage is None or stage == \"fit\":\n",
    "            self.data_train = self.setup_dataset(\"train\")\n",
    "            self.data_val = self.setup_dataset(\"val\")\n",
    "        if stage == \"test\":\n",
    "            self.data_test = self.setup_dataset(\"test\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "\n",
    "dm = MetaDataModule()\n",
    "# dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8008.759886311375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.train_dataloader()) /len(dm.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18484523"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split, Subset\n",
    "\n",
    "a = Subset(dm.data_train, random.sample(range(len(dm.data_train)), 10000))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72456202622, 3229094326080, 8197011685343, 7348473393976, 4594789866374]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('support',\n",
       "              <torchmeta.utils.data.task.SubsetTask at 0x1a431b72310>),\n",
       "             ('query',\n",
       "              <torchmeta.utils.data.task.SubsetTask at 0x1a431b72370>)])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.sample(range(len(dm.data_train)), 5)\n",
    "print(i)\n",
    "dm.data_train[20, 20, 20, 1027, 1027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('support',\n",
       "              <torchmeta.utils.data.task.SubsetTask at 0x1a431ba97f0>),\n",
       "             ('query',\n",
       "              <torchmeta.utils.data.task.SubsetTask at 0x1a431ba9850>)])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.data_train.__getitem__([0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Omniglot in module torchmeta.datasets.omniglot object:\n",
      "\n",
      "class Omniglot(torchmeta.utils.data.dataset.CombinationMetaDataset)\n",
      " |  Omniglot(root, num_classes_per_task=None, meta_train=False, meta_val=False, meta_test=False, meta_split=None, use_vinyals_split=True, transform=None, target_transform=None, dataset_transform=None, class_augmentations=None, download=False)\n",
      " |  \n",
      " |  The Omniglot dataset [1]. A dataset of 1623 handwritten characters from \n",
      " |  50 different alphabets. \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  root : string\n",
      " |      Root directory where the dataset folder `omniglot` exists.\n",
      " |  \n",
      " |  num_classes_per_task : int\n",
      " |      Number of classes per tasks. This corresponds to \"N\" in \"N-way\" \n",
      " |      classification.\n",
      " |  \n",
      " |  meta_train : bool (default: `False`)\n",
      " |      Use the meta-train split of the dataset. If set to `True`, then the\n",
      " |      arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n",
      " |      of these three arguments must be set to `True`.\n",
      " |  \n",
      " |  meta_val : bool (default: `False`)\n",
      " |      Use the meta-validation split of the dataset. If set to `True`, then the \n",
      " |      arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n",
      " |      of these three arguments must be set to `True`.\n",
      " |  \n",
      " |  meta_test : bool (default: `False`)\n",
      " |      Use the meta-test split of the dataset. If set to `True`, then the \n",
      " |      arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n",
      " |      of these three arguments must be set to `True`.\n",
      " |  \n",
      " |  meta_split : string in {'train', 'val', 'test'}, optional\n",
      " |      Name of the split to use. This overrides the arguments `meta_train`, \n",
      " |      `meta_val` and `meta_test` if all three are set to `False`.\n",
      " |  \n",
      " |  use_vinyals_split : bool (default: `True`)\n",
      " |      If set to `True`, the dataset uses the splits defined in [3]. If `False`, \n",
      " |      then the meta-train split corresponds to `images_background`, and the \n",
      " |      meta-test split corresponds to `images_evaluation` (raises an error when \n",
      " |      calling the meta-validation split).\n",
      " |  \n",
      " |  transform : callable, optional\n",
      " |      A function/transform that takes a `PIL` image, and returns a transformed \n",
      " |      version. See also `torchvision.transforms`.\n",
      " |  \n",
      " |  target_transform : callable, optional\n",
      " |      A function/transform that takes a target, and returns a transformed \n",
      " |      version. See also `torchvision.transforms`.\n",
      " |  \n",
      " |  dataset_transform : callable, optional\n",
      " |      A function/transform that takes a dataset (ie. a task), and returns a \n",
      " |      transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n",
      " |  \n",
      " |  class_augmentations : list of callable, optional\n",
      " |      A list of functions that augment the dataset with new classes. These classes \n",
      " |      are transformations of existing classes. E.g.\n",
      " |      `torchmeta.transforms.HorizontalFlip()`.\n",
      " |  \n",
      " |  download : bool (default: `False`)\n",
      " |      If `True`, downloads the zip files and processes the dataset in the root \n",
      " |      directory (under the `omniglot` folder). If the dataset is already \n",
      " |      available, this does not download/process the dataset again.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The dataset is downloaded from the original [Omniglot repository]\n",
      " |  (https://github.com/brendenlake/omniglot). The meta train/validation/test \n",
      " |  splits used in [3] are taken from [this repository]\n",
      " |  (https://github.com/jakesnell/prototypical-networks). These splits are \n",
      " |  over 1028/172/423 classes (characters).\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level \n",
      " |         concept learning through probabilistic program induction. Science, 350(6266), \n",
      " |         1332-1338 (http://www.sciencemag.org/content/350/6266/1332.short)\n",
      " |  \n",
      " |  .. [2] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2019). The Omniglot \n",
      " |         Challenge: A 3-Year Progress Report (https://arxiv.org/abs/1902.03477)\n",
      " |  \n",
      " |  .. [3] Vinyals, O., Blundell, C., Lillicrap, T. and Wierstra, D. (2016). \n",
      " |         Matching Networks for One Shot Learning. In Advances in Neural \n",
      " |         Information Processing Systems (pp. 3630-3638) (https://arxiv.org/abs/1606.04080)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Omniglot\n",
      " |      torchmeta.utils.data.dataset.CombinationMetaDataset\n",
      " |      torchmeta.utils.data.dataset.MetaDataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root, num_classes_per_task=None, meta_train=False, meta_val=False, meta_test=False, meta_split=None, use_vinyals_split=True, transform=None, target_transform=None, dataset_transform=None, class_augmentations=None, download=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchmeta.utils.data.dataset.CombinationMetaDataset:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  sample_task(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchmeta.utils.data.dataset.MetaDataset:\n",
      " |  \n",
      " |  seed(self, seed=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from torchmeta.utils.data.dataset.MetaDataset:\n",
      " |  \n",
      " |  meta_split\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torchmeta.utils.data.dataset.MetaDataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dm.data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copy from torchmeta.utils.data.sampler.CombinationRandomSampler\n",
    "Add num_samples parameter to __init__ for select num_samples from dataset\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from torchmeta.utils.data.dataset import CombinationMetaDataset\n",
    "\n",
    "\n",
    "class CombinationRandomSampler(RandomSampler):\n",
    "    def __init__(self, data_source, num_samples):\n",
    "        if not isinstance(data_source, CombinationMetaDataset):\n",
    "            raise TypeError('Expected `data_source` to be an instance of '\n",
    "                            '`CombinationMetaDataset`, but found '\n",
    "                            '{0}'.format(type(data_source)))\n",
    "        # Temporarily disable the warning if the length of the length of the \n",
    "        # dataset exceeds the machine precision. This avoids getting this\n",
    "        # warning shown with MetaDataLoader, even though MetaDataLoader itself\n",
    "        # does not use the length of the dataset.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            super(CombinationRandomSampler, self).__init__(data_source,\n",
    "                                                           replacement=True,\n",
    "                                                           num_samples=num_samples)\n",
    "\n",
    "    def __iter__(self):\n",
    "        num_classes = len(self.data_source.dataset)\n",
    "        num_classes_per_task = self.data_source.num_classes_per_task\n",
    "        for _ in combinations(range(num_classes), num_classes_per_task):\n",
    "            yield tuple(random.sample(range(num_classes), num_classes_per_task))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CombinationRandomSampler' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28172\\1746500114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCombinationRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'CombinationRandomSampler' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(CombinationRandomSampler(dm.data_train, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "110*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393.8317262028157"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9474438804480**(1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9474438804480.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1028*1027*1026*1025*1024/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142489501553907"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1027**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28172\\979717267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_sampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('support',\n",
       "              <torchmeta.utils.data.task.SubsetTask at 0x1a43165ad90>),\n",
       "             ('query',\n",
       "              <torchmeta.utils.data.task.SubsetTask at 0x1a43165ad00>)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.data_train.sample_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.utils.data.Subset(dm.data_train, [*range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MetaDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28172\\4006348962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMetaDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'MetaDataset' is not defined"
     ]
    }
   ],
   "source": [
    "help(CombinationMetaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchmeta.utils.data.dataset.CombinationMetaDataset"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CombinationMetaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Omniglot in module torchmeta.datasets.omniglot object:\n",
      "\n",
      "class Omniglot(torchmeta.utils.data.dataset.CombinationMetaDataset)\n",
      " |  Omniglot(root, num_classes_per_task=None, meta_train=False, meta_val=False, meta_test=False, meta_split=None, use_vinyals_split=True, transform=None, target_transform=None, dataset_transform=None, class_augmentations=None, download=False)\n",
      " |  \n",
      " |  The Omniglot dataset [1]. A dataset of 1623 handwritten characters from \n",
      " |  50 different alphabets. \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  root : string\n",
      " |      Root directory where the dataset folder `omniglot` exists.\n",
      " |  \n",
      " |  num_classes_per_task : int\n",
      " |      Number of classes per tasks. This corresponds to \"N\" in \"N-way\" \n",
      " |      classification.\n",
      " |  \n",
      " |  meta_train : bool (default: `False`)\n",
      " |      Use the meta-train split of the dataset. If set to `True`, then the\n",
      " |      arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n",
      " |      of these three arguments must be set to `True`.\n",
      " |  \n",
      " |  meta_val : bool (default: `False`)\n",
      " |      Use the meta-validation split of the dataset. If set to `True`, then the \n",
      " |      arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n",
      " |      of these three arguments must be set to `True`.\n",
      " |  \n",
      " |  meta_test : bool (default: `False`)\n",
      " |      Use the meta-test split of the dataset. If set to `True`, then the \n",
      " |      arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n",
      " |      of these three arguments must be set to `True`.\n",
      " |  \n",
      " |  meta_split : string in {'train', 'val', 'test'}, optional\n",
      " |      Name of the split to use. This overrides the arguments `meta_train`, \n",
      " |      `meta_val` and `meta_test` if all three are set to `False`.\n",
      " |  \n",
      " |  use_vinyals_split : bool (default: `True`)\n",
      " |      If set to `True`, the dataset uses the splits defined in [3]. If `False`, \n",
      " |      then the meta-train split corresponds to `images_background`, and the \n",
      " |      meta-test split corresponds to `images_evaluation` (raises an error when \n",
      " |      calling the meta-validation split).\n",
      " |  \n",
      " |  transform : callable, optional\n",
      " |      A function/transform that takes a `PIL` image, and returns a transformed \n",
      " |      version. See also `torchvision.transforms`.\n",
      " |  \n",
      " |  target_transform : callable, optional\n",
      " |      A function/transform that takes a target, and returns a transformed \n",
      " |      version. See also `torchvision.transforms`.\n",
      " |  \n",
      " |  dataset_transform : callable, optional\n",
      " |      A function/transform that takes a dataset (ie. a task), and returns a \n",
      " |      transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n",
      " |  \n",
      " |  class_augmentations : list of callable, optional\n",
      " |      A list of functions that augment the dataset with new classes. These classes \n",
      " |      are transformations of existing classes. E.g.\n",
      " |      `torchmeta.transforms.HorizontalFlip()`.\n",
      " |  \n",
      " |  download : bool (default: `False`)\n",
      " |      If `True`, downloads the zip files and processes the dataset in the root \n",
      " |      directory (under the `omniglot` folder). If the dataset is already \n",
      " |      available, this does not download/process the dataset again.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The dataset is downloaded from the original [Omniglot repository]\n",
      " |  (https://github.com/brendenlake/omniglot). The meta train/validation/test \n",
      " |  splits used in [3] are taken from [this repository]\n",
      " |  (https://github.com/jakesnell/prototypical-networks). These splits are \n",
      " |  over 1028/172/423 classes (characters).\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level \n",
      " |         concept learning through probabilistic program induction. Science, 350(6266), \n",
      " |         1332-1338 (http://www.sciencemag.org/content/350/6266/1332.short)\n",
      " |  \n",
      " |  .. [2] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2019). The Omniglot \n",
      " |         Challenge: A 3-Year Progress Report (https://arxiv.org/abs/1902.03477)\n",
      " |  \n",
      " |  .. [3] Vinyals, O., Blundell, C., Lillicrap, T. and Wierstra, D. (2016). \n",
      " |         Matching Networks for One Shot Learning. In Advances in Neural \n",
      " |         Information Processing Systems (pp. 3630-3638) (https://arxiv.org/abs/1606.04080)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Omniglot\n",
      " |      torchmeta.utils.data.dataset.CombinationMetaDataset\n",
      " |      torchmeta.utils.data.dataset.MetaDataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root, num_classes_per_task=None, meta_train=False, meta_val=False, meta_test=False, meta_split=None, use_vinyals_split=True, transform=None, target_transform=None, dataset_transform=None, class_augmentations=None, download=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchmeta.utils.data.dataset.CombinationMetaDataset:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  sample_task(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchmeta.utils.data.dataset.MetaDataset:\n",
      " |  \n",
      " |  seed(self, seed=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from torchmeta.utils.data.dataset.MetaDataset:\n",
      " |  \n",
      " |  meta_split\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torchmeta.utils.data.dataset.MetaDataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dm.data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9474438804480"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9474438804480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9474438804480/592152425280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30540613468033.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "152703067340165/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                           | 0/152703067340165 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "with tqdm(dm.train_dataloader(), total=len(dm.train_dataloader())) as pbar:\n",
    "    for batch_idx, batch in enumerate(pbar):        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['support', 'query'])\n",
      "torch.Size([64, 25, 1, 28, 28])\n",
      "torch.Size([64, 25])\n"
     ]
    }
   ],
   "source": [
    "print(batch.keys())\n",
    "\n",
    "x, y = batch['support']\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 1, 28, 28])\n",
      "torch.Size([64, 25])\n"
     ]
    }
   ],
   "source": [
    "x, y = batch['query']\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 2, 2, 2, 2,\n",
       "        2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
